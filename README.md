<h1 align="center">Factors of Influence on <br/> End-to-End Continuous Spanish Lipreading</h1>

Thanks to the availability of large-scale audiovisual databases and the use of powerful attention-based mechanisms, unprecedented results have been achieved in Visual Speech Recognition. However, the use of these technologies in other languages than English is quite limited. In our paper, in addition to studying how the different components that form the architecture influence the quality of speech recognition, we presented a new Spanish Lipreading Benchmark. It covers diverse scenarios with different recording settings, speaker-dependent and speaker-independent experiments, as well as data-scarcity databases.


Visual speech recognition remains an open research problem
where, by dispensing with the auditory sense, different chal-
lenges must be considered. Nonetheless, thanks to the avail-
ability of large-scale databases and the use of powerful atten-
tion mechanisms, recent remarkable results have been achieved
in the field. Besides, multiple languages apart from English are
nowadays a focus of interest. This paper presents noticeable ad-
vances in automatic continuous lipreading for Spanish. First, an
end-to-end system based on the hybrid CTC/Attention architec-
ture is presented. Experiments are conducted on two corpora of
disparate nature, reaching state-of-the-art results which signif-
icantly improve the best performance obtained to date for both
databases. In addition, a thorough ablation study is carried out,
where it is studied how the different components that form the
architecture influence the quality of speech recognition. Finally,
a new Spanish lipreading benchmark is consolidated

<details open>
  <summary><b>Spanish Lipreading Benchmark</b></summary>

<p> </p>
  
|            Models          |     %WER    |               Download               |  size (MB)  |
|:---------------------------|:-----------:|:------------------------------------:|:-----------:|
|  **LIP-RTVE**              |            
|  **speaker-independent**   |  59.5 ± 1.2 | [GoogleDrive](http://bit.ly/40EAtyX) |     211     |
|  **speaker-dependent**     |  34.2 ± 1.2 | [GoogleDrive](http://bit.ly/40EAtyX) |     211     |
|  Language Model            |      -      | [GoogleDrive](http://bit.ly/40EAtyX) |     203     |
|  Landmarks                 |      -      | [GoogleDrive](http://bit.ly/40EAtyX) |     562     |
|  -                         |             |                                      |             |
|  **VLRF**                  |
|  **speaker-dependent**     |  24.8 ± 3.4 | [GoogleDrive](http://bit.ly/40EAtyX) |     211     |
|  Language Model            |      -      | [GoogleDrive](http://bit.ly/40EAtyX) |     203     |
|  Landmarks                 |      -      | [GoogleDrive](http://bit.ly/40EAtyX) |     260     |
|  -                         |             |                                      |             |
|  **CMU-MOSEAS**            |
|  **speaker-independent**   |  44.6 ± 0.6 | [GoogleDrive](http://bit.ly/3yRSXAn) |     211     |
|  Language Model            |      -      | [GoogleDrive](http://bit.ly/40EAtyX) |     203     |
|  Landmarks                 |      -      | [GoogleDrive](http://bit.ly/40EAtyX) |     3187    |
|  -                         |             |                                      |             |
|  **Multilingual-TEDx**     |
|  **speaker-independent**   |  56.3 ± 0.3 | [GoogleDrive](http://bit.ly/3yRSXAn) |     211     |
|  Language Model            |      -      | [GoogleDrive](http://bit.ly/40EAtyX) |     203     |
|  Landmarks                 |      -      | [GoogleDrive](http://bit.ly/40EAtyX) |     3143    |

</details>
