# lm related
lm: transformer
lm_conf:
  pos_enc:
  embed_unit: 128
  att_unit: 512
  head: 8
  unit: 2048
  layer: 16
  dropout_rate: 0.0

# espnet model related
model_conf:
  ignore_id: -1

# other details
init: "chainer"
token_list: [
  "<blank>",
  "<unk>",
  "<space>",
  "a",
  "b",
  "c",
  "d",
  "e",
  "f",
  "g",
  "h",
  "i",
  "j",
  "k",
  "l",
  "m",
  "n",
  "o",
  "p",
  "q",
  "r",
  "s",
  "t",
  "u",
  "v",
  "w",
  "x",
  "y",
  "z",
  "á",
  "é",
  "í",
  "ñ",
  "ó",
  "ú",
  "ü",
  "<sos/eos>",
  ]
